{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WfZBAAJ4tcj"
   },
   "source": [
    "# cDLinear; F = 10; T = 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhm6IGfJ445r",
    "outputId": "ca807d43-3c41-4fa0-ee28-58d74170d05a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-2ECVf6_5IV3",
    "outputId": "460097da-4755-46fd-8414-b3510dcfe706"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ngcausality'...\n",
      "remote: Enumerating objects: 135, done.\u001b[K\n",
      "remote: Counting objects: 100% (135/135), done.\u001b[K\n",
      "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
      "remote: Total 135 (delta 58), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (135/135), 1.08 MiB | 11.60 MiB/s, done.\n",
      "Resolving deltas: 100% (58/58), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://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@github.com/Proton1121/ngcausality.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avf5RXuU50ck",
    "outputId": "86a51a0d-7539-4134-b67e-9d41f4b0056b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/ngcausality\n"
     ]
    }
   ],
   "source": [
    "%cd /content/ngcausality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_FBbOyQ-4tcm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data.synthetic import simulate_lorenz_96\n",
    "from data.dream import generate_causal_matrix\n",
    "from models.cdlinear import cDLinear, train_model_ista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hEbcASByB-7M"
   },
   "outputs": [],
   "source": [
    "save_dir = '/content/drive/MyDrive/ngcausality_results/' + 'loren_f10_t250/'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kkQyyD7B4tco"
   },
   "outputs": [],
   "source": [
    "# For GPU acceleration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "AFaFwK384tcp"
   },
   "outputs": [],
   "source": [
    "# Simulate data\n",
    "X_np, GC = simulate_lorenz_96(p=20, F=10, T=250)\n",
    "X = torch.tensor(X_np[np.newaxis], dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "KqL4DxxjEe84"
   },
   "outputs": [],
   "source": [
    "# Save the simulated data to Google Drive\n",
    "np.save(os.path.join(save_dir, 'X_np.npy'), X_np)  # Save X_np (simulated data)\n",
    "np.save(os.path.join(save_dir, 'GC.npy'), GC)  # Save GC (Granger causality matrix)\n",
    "\n",
    "torch.save(X, os.path.join(save_dir, 'X_tensor.pt'))\n",
    "\n",
    "with open(os.path.join(save_dir, 'data_shapes.txt'), 'w') as f:\n",
    "    f.write(f'Shape of X_np: {X_np.shape}\\n')\n",
    "    f.write(f'Shape of GC: {GC.shape}\\n')\n",
    "    f.write(f'Shape of X (torch tensor): {X.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "F3SH5MCp4tcr"
   },
   "outputs": [],
   "source": [
    "# Plot data\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
    "axarr[0].plot(X_np)\n",
    "axarr[0].set_xlabel('T')\n",
    "axarr[0].set_title('Entire time series')\n",
    "axarr[1].plot(X_np[:50])\n",
    "axarr[1].set_xlabel('T')\n",
    "axarr[1].set_title('First 50 time points')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Step 5: Save the plot to Google Drive\n",
    "plot_filename = os.path.join(save_dir, 'data_plots.png')\n",
    "plt.savefig(plot_filename)  # Save the plot as a PNG file in Google Drive\n",
    "\n",
    "# Optionally, close the plot to prevent it from displaying in the notebook (you can skip this if you want to see it in the notebook)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njNLOBz74tcs",
    "outputId": "67b80f44-df06-43d7-fa0c-54497cec14db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Iter = 100----------\n",
      "Loss = 820.152283\n",
      "nonsmooth = 690.540466\n",
      "smooth = 129.611786\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 200----------\n",
      "Loss = 772.074646\n",
      "nonsmooth = 651.128052\n",
      "smooth = 120.946556\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 300----------\n",
      "Loss = 729.241882\n",
      "nonsmooth = 611.656006\n",
      "smooth = 117.585915\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 400----------\n",
      "Loss = 688.196350\n",
      "nonsmooth = 572.117065\n",
      "smooth = 116.079285\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 500----------\n",
      "Loss = 647.858215\n",
      "nonsmooth = 532.546753\n",
      "smooth = 115.311485\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 600----------\n",
      "Loss = 607.848206\n",
      "nonsmooth = 492.976166\n",
      "smooth = 114.872025\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 700----------\n",
      "Loss = 568.025818\n",
      "nonsmooth = 453.429535\n",
      "smooth = 114.596245\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 800----------\n",
      "Loss = 528.339478\n",
      "nonsmooth = 413.926971\n",
      "smooth = 114.412529\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 900----------\n",
      "Loss = 488.776764\n",
      "nonsmooth = 374.489014\n",
      "smooth = 114.287720\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 1000----------\n",
      "Loss = 449.342926\n",
      "nonsmooth = 335.136658\n",
      "smooth = 114.206291\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 1100----------\n",
      "Loss = 410.057861\n",
      "nonsmooth = 295.895966\n",
      "smooth = 114.161903\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 1200----------\n",
      "Loss = 370.957489\n",
      "nonsmooth = 256.803497\n",
      "smooth = 114.154007\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 1300----------\n",
      "Loss = 332.100067\n",
      "nonsmooth = 217.912674\n",
      "smooth = 114.187378\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 1400----------\n",
      "Loss = 293.581787\n",
      "nonsmooth = 179.308014\n",
      "smooth = 114.273766\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 1500----------\n",
      "Loss = 255.574860\n",
      "nonsmooth = 141.136917\n",
      "smooth = 114.437950\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 1600----------\n",
      "Loss = 218.430527\n",
      "nonsmooth = 103.694084\n",
      "smooth = 114.736427\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 1700----------\n",
      "Loss = 183.037354\n",
      "nonsmooth = 67.708725\n",
      "smooth = 115.328629\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 1800----------\n",
      "Loss = 152.655792\n",
      "nonsmooth = 35.790813\n",
      "smooth = 116.864967\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 1900----------\n",
      "Loss = 138.887177\n",
      "nonsmooth = 18.289253\n",
      "smooth = 120.597916\n",
      "Variable usage = 90.75%\n",
      "----------Iter = 2000----------\n",
      "Loss = 137.065842\n",
      "nonsmooth = 15.097579\n",
      "smooth = 121.968254\n",
      "Variable usage = 82.25%\n",
      "----------Iter = 2100----------\n",
      "Loss = 136.311401\n",
      "nonsmooth = 14.414451\n",
      "smooth = 121.896950\n",
      "Variable usage = 83.00%\n",
      "----------Iter = 2200----------\n",
      "Loss = 135.721909\n",
      "nonsmooth = 14.093027\n",
      "smooth = 121.628868\n",
      "Variable usage = 85.00%\n",
      "----------Iter = 2300----------\n",
      "Loss = 135.224228\n",
      "nonsmooth = 13.874930\n",
      "smooth = 121.349297\n",
      "Variable usage = 86.50%\n",
      "----------Iter = 2400----------\n",
      "Loss = 134.791183\n",
      "nonsmooth = 13.707416\n",
      "smooth = 121.083763\n",
      "Variable usage = 87.75%\n",
      "----------Iter = 2500----------\n",
      "Loss = 134.404892\n",
      "nonsmooth = 13.570399\n",
      "smooth = 120.834496\n",
      "Variable usage = 89.50%\n",
      "----------Iter = 2600----------\n",
      "Loss = 134.053253\n",
      "nonsmooth = 13.453620\n",
      "smooth = 120.599625\n",
      "Variable usage = 90.50%\n",
      "----------Iter = 2700----------\n",
      "Loss = 133.728378\n",
      "nonsmooth = 13.347713\n",
      "smooth = 120.380653\n",
      "Variable usage = 91.00%\n",
      "----------Iter = 2800----------\n",
      "Loss = 133.425095\n",
      "nonsmooth = 13.248092\n",
      "smooth = 120.177002\n",
      "Variable usage = 92.00%\n",
      "----------Iter = 2900----------\n",
      "Loss = 133.140091\n",
      "nonsmooth = 13.152946\n",
      "smooth = 119.987144\n",
      "Variable usage = 93.00%\n",
      "----------Iter = 3000----------\n",
      "Loss = 132.870956\n",
      "nonsmooth = 13.061042\n",
      "smooth = 119.809898\n",
      "Variable usage = 93.00%\n",
      "----------Iter = 3100----------\n",
      "Loss = 132.615891\n",
      "nonsmooth = 12.971442\n",
      "smooth = 119.644463\n",
      "Variable usage = 93.50%\n",
      "----------Iter = 3200----------\n",
      "Loss = 132.373581\n",
      "nonsmooth = 12.884297\n",
      "smooth = 119.489281\n",
      "Variable usage = 93.50%\n",
      "----------Iter = 3300----------\n",
      "Loss = 132.142853\n",
      "nonsmooth = 12.799823\n",
      "smooth = 119.343033\n",
      "Variable usage = 94.25%\n",
      "----------Iter = 3400----------\n",
      "Loss = 131.922760\n",
      "nonsmooth = 12.718140\n",
      "smooth = 119.204613\n",
      "Variable usage = 94.75%\n",
      "----------Iter = 3500----------\n",
      "Loss = 131.712448\n",
      "nonsmooth = 12.638768\n",
      "smooth = 119.073685\n",
      "Variable usage = 95.25%\n",
      "----------Iter = 3600----------\n",
      "Loss = 131.511154\n",
      "nonsmooth = 12.561500\n",
      "smooth = 118.949661\n",
      "Variable usage = 95.50%\n",
      "----------Iter = 3700----------\n",
      "Loss = 131.318237\n",
      "nonsmooth = 12.486099\n",
      "smooth = 118.832146\n",
      "Variable usage = 96.00%\n",
      "----------Iter = 3800----------\n",
      "Loss = 131.133148\n",
      "nonsmooth = 12.412692\n",
      "smooth = 118.720451\n",
      "Variable usage = 96.25%\n",
      "----------Iter = 3900----------\n",
      "Loss = 130.955353\n",
      "nonsmooth = 12.340913\n",
      "smooth = 118.614433\n",
      "Variable usage = 96.50%\n",
      "----------Iter = 4000----------\n",
      "Loss = 130.784317\n",
      "nonsmooth = 12.270556\n",
      "smooth = 118.513756\n",
      "Variable usage = 96.50%\n",
      "----------Iter = 4100----------\n",
      "Loss = 130.619675\n",
      "nonsmooth = 12.201533\n",
      "smooth = 118.418129\n",
      "Variable usage = 96.50%\n",
      "----------Iter = 4200----------\n",
      "Loss = 130.460999\n",
      "nonsmooth = 12.133849\n",
      "smooth = 118.327148\n",
      "Variable usage = 96.75%\n",
      "----------Iter = 4300----------\n",
      "Loss = 130.307953\n",
      "nonsmooth = 12.067751\n",
      "smooth = 118.240196\n",
      "Variable usage = 97.00%\n",
      "----------Iter = 4400----------\n",
      "Loss = 130.160187\n",
      "nonsmooth = 12.003087\n",
      "smooth = 118.157097\n",
      "Variable usage = 97.00%\n",
      "----------Iter = 4500----------\n",
      "Loss = 130.017380\n",
      "nonsmooth = 11.939679\n",
      "smooth = 118.077713\n",
      "Variable usage = 97.00%\n",
      "----------Iter = 4600----------\n",
      "Loss = 129.879318\n",
      "nonsmooth = 11.877709\n",
      "smooth = 118.001610\n",
      "Variable usage = 97.25%\n",
      "----------Iter = 4700----------\n",
      "Loss = 129.745697\n",
      "nonsmooth = 11.817022\n",
      "smooth = 117.928673\n",
      "Variable usage = 97.25%\n",
      "----------Iter = 4800----------\n",
      "Loss = 129.616257\n",
      "nonsmooth = 11.757609\n",
      "smooth = 117.858643\n",
      "Variable usage = 97.50%\n",
      "----------Iter = 4900----------\n",
      "Loss = 129.490768\n",
      "nonsmooth = 11.699437\n",
      "smooth = 117.791336\n",
      "Variable usage = 97.50%\n",
      "----------Iter = 5000----------\n",
      "Loss = 129.369095\n",
      "nonsmooth = 11.642389\n",
      "smooth = 117.726707\n",
      "Variable usage = 97.75%\n",
      "----------Iter = 5100----------\n",
      "Loss = 129.250992\n",
      "nonsmooth = 11.586759\n",
      "smooth = 117.664238\n",
      "Variable usage = 98.00%\n",
      "----------Iter = 5200----------\n",
      "Loss = 129.136276\n",
      "nonsmooth = 11.532268\n",
      "smooth = 117.604019\n",
      "Variable usage = 98.00%\n",
      "----------Iter = 5300----------\n",
      "Loss = 129.024780\n",
      "nonsmooth = 11.478797\n",
      "smooth = 117.545982\n",
      "Variable usage = 98.00%\n",
      "----------Iter = 5400----------\n",
      "Loss = 128.916397\n",
      "nonsmooth = 11.426321\n",
      "smooth = 117.490074\n",
      "Variable usage = 98.00%\n",
      "----------Iter = 5500----------\n",
      "Loss = 128.810928\n",
      "nonsmooth = 11.374854\n",
      "smooth = 117.436073\n",
      "Variable usage = 98.25%\n",
      "----------Iter = 5600----------\n",
      "Loss = 128.708267\n",
      "nonsmooth = 11.324337\n",
      "smooth = 117.383926\n",
      "Variable usage = 98.25%\n",
      "----------Iter = 5700----------\n",
      "Loss = 128.608261\n",
      "nonsmooth = 11.274736\n",
      "smooth = 117.333519\n",
      "Variable usage = 98.25%\n",
      "----------Iter = 5800----------\n",
      "Loss = 128.510849\n",
      "nonsmooth = 11.226029\n",
      "smooth = 117.284813\n",
      "Variable usage = 98.25%\n",
      "----------Iter = 5900----------\n",
      "Loss = 128.415863\n",
      "nonsmooth = 11.178348\n",
      "smooth = 117.237511\n",
      "Variable usage = 98.75%\n",
      "----------Iter = 6000----------\n",
      "Loss = 128.323242\n",
      "nonsmooth = 11.131543\n",
      "smooth = 117.191704\n",
      "Variable usage = 98.75%\n",
      "----------Iter = 6100----------\n",
      "Loss = 128.232834\n",
      "nonsmooth = 11.085586\n",
      "smooth = 117.147240\n",
      "Variable usage = 99.00%\n",
      "----------Iter = 6200----------\n",
      "Loss = 128.144592\n",
      "nonsmooth = 11.040549\n",
      "smooth = 117.104042\n",
      "Variable usage = 99.00%\n",
      "----------Iter = 6300----------\n",
      "Loss = 128.058426\n",
      "nonsmooth = 10.996284\n",
      "smooth = 117.062134\n",
      "Variable usage = 99.00%\n",
      "----------Iter = 6400----------\n",
      "Loss = 127.974197\n",
      "nonsmooth = 10.952838\n",
      "smooth = 117.021362\n",
      "Variable usage = 99.25%\n",
      "----------Iter = 6500----------\n",
      "Loss = 127.891884\n",
      "nonsmooth = 10.910148\n",
      "smooth = 116.981743\n",
      "Variable usage = 99.25%\n",
      "----------Iter = 6600----------\n",
      "Loss = 127.811424\n",
      "nonsmooth = 10.868168\n",
      "smooth = 116.943260\n",
      "Variable usage = 99.25%\n",
      "----------Iter = 6700----------\n",
      "Loss = 127.732704\n",
      "nonsmooth = 10.826877\n",
      "smooth = 116.905823\n",
      "Variable usage = 99.25%\n",
      "----------Iter = 6800----------\n",
      "Loss = 127.655678\n",
      "nonsmooth = 10.786258\n",
      "smooth = 116.869423\n",
      "Variable usage = 99.25%\n",
      "----------Iter = 6900----------\n",
      "Loss = 127.580299\n",
      "nonsmooth = 10.746333\n",
      "smooth = 116.833961\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 7000----------\n",
      "Loss = 127.506470\n",
      "nonsmooth = 10.707084\n",
      "smooth = 116.799393\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 7100----------\n",
      "Loss = 127.434196\n",
      "nonsmooth = 10.668454\n",
      "smooth = 116.765739\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 7200----------\n",
      "Loss = 127.363342\n",
      "nonsmooth = 10.630429\n",
      "smooth = 116.732910\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 7300----------\n",
      "Loss = 127.293922\n",
      "nonsmooth = 10.592994\n",
      "smooth = 116.700928\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 7400----------\n",
      "Loss = 127.225853\n",
      "nonsmooth = 10.556133\n",
      "smooth = 116.669731\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 7500----------\n",
      "Loss = 127.159111\n",
      "nonsmooth = 10.519832\n",
      "smooth = 116.639275\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 7600----------\n",
      "Loss = 127.093651\n",
      "nonsmooth = 10.484077\n",
      "smooth = 116.609573\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 7700----------\n",
      "Loss = 127.029381\n",
      "nonsmooth = 10.448856\n",
      "smooth = 116.580528\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 7800----------\n",
      "Loss = 126.966362\n",
      "nonsmooth = 10.414157\n",
      "smooth = 116.552200\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 7900----------\n",
      "Loss = 126.904472\n",
      "nonsmooth = 10.379962\n",
      "smooth = 116.524513\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 8000----------\n",
      "Loss = 126.843712\n",
      "nonsmooth = 10.346264\n",
      "smooth = 116.497452\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 8100----------\n",
      "Loss = 126.784019\n",
      "nonsmooth = 10.313049\n",
      "smooth = 116.470970\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 8200----------\n",
      "Loss = 126.725395\n",
      "nonsmooth = 10.280309\n",
      "smooth = 116.445084\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 8300----------\n",
      "Loss = 126.667786\n",
      "nonsmooth = 10.248028\n",
      "smooth = 116.419762\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 8400----------\n",
      "Loss = 126.611168\n",
      "nonsmooth = 10.216199\n",
      "smooth = 116.394974\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 8500----------\n",
      "Loss = 126.555496\n",
      "nonsmooth = 10.184810\n",
      "smooth = 116.370682\n",
      "Variable usage = 99.50%\n",
      "----------Iter = 8600----------\n",
      "Loss = 126.500755\n",
      "nonsmooth = 10.153883\n",
      "smooth = 116.346878\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 8700----------\n",
      "Loss = 126.453728\n",
      "nonsmooth = 10.124428\n",
      "smooth = 116.329300\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 8800----------\n",
      "Loss = 126.428467\n",
      "nonsmooth = 10.120772\n",
      "smooth = 116.307693\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 8900----------\n",
      "Loss = 126.374840\n",
      "nonsmooth = 10.083262\n",
      "smooth = 116.291580\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 9000----------\n",
      "Loss = 126.322998\n",
      "nonsmooth = 10.053740\n",
      "smooth = 116.269264\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 9100----------\n",
      "Loss = 126.281227\n",
      "nonsmooth = 10.025421\n",
      "smooth = 116.255814\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 9200----------\n",
      "Loss = 126.253113\n",
      "nonsmooth = 10.018722\n",
      "smooth = 116.234390\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 9300----------\n",
      "Loss = 135.668686\n",
      "nonsmooth = 10.249428\n",
      "smooth = 125.419250\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 9400----------\n",
      "Loss = 126.238335\n",
      "nonsmooth = 9.974418\n",
      "smooth = 116.263916\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 9500----------\n",
      "Loss = 126.206116\n",
      "nonsmooth = 9.995116\n",
      "smooth = 116.210999\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 9600----------\n",
      "Loss = 126.187805\n",
      "nonsmooth = 9.985927\n",
      "smooth = 116.201881\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 9700----------\n",
      "Loss = 126.243874\n",
      "nonsmooth = 10.014858\n",
      "smooth = 116.229019\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 9800----------\n",
      "Loss = 126.371216\n",
      "nonsmooth = 9.981068\n",
      "smooth = 116.390152\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 9900----------\n",
      "Loss = 126.171570\n",
      "nonsmooth = 9.968167\n",
      "smooth = 116.203407\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 10000----------\n",
      "Loss = 152.516876\n",
      "nonsmooth = 10.536186\n",
      "smooth = 141.980698\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 10100----------\n",
      "Loss = 126.235229\n",
      "nonsmooth = 10.021393\n",
      "smooth = 116.213829\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 10200----------\n",
      "Loss = 126.253601\n",
      "nonsmooth = 10.018325\n",
      "smooth = 116.235283\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 10300----------\n",
      "Loss = 126.467972\n",
      "nonsmooth = 10.033099\n",
      "smooth = 116.434875\n",
      "Variable usage = 99.75%\n",
      "----------Iter = 10400----------\n",
      "Loss = 127.136169\n",
      "nonsmooth = 10.026722\n",
      "smooth = 117.109451\n",
      "Variable usage = 99.75%\n",
      "Stopping early\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "  save_dir = '/content/drive/MyDrive/ngcausality_results/' + 'loren_f10_t250/' + str(1+5*i) + '/'\n",
    "\n",
    "  if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "  #Set up model\n",
    "  cdlinear = cDLinear(X.shape[-1], hidden=100, lag=5).to(device=device)\n",
    "\n",
    "  # Train with ISTA\n",
    "  train_loss_list = train_model_ista(\n",
    "    cdlinear, X, lam=(1+5*i), lam_ridge=1e-5, lr=5e-5, penalty='H', max_iter=50000,\n",
    "    check_every=100)\n",
    "\n",
    "  # Loss function plot\n",
    "  plt.figure(figsize=(8, 5))\n",
    "  train_loss_np = [loss.cpu().detach().numpy() for loss in train_loss_list]\n",
    "  plt.plot(50 * np.arange(len(train_loss_np)), train_loss_np)\n",
    "  plt.title('cDLinear training')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Training steps')\n",
    "  plt.tight_layout()\n",
    "  loss_plot_path = os.path.join(save_dir, f'loss_plot_{1+5*i}.png')\n",
    "  plt.savefig(loss_plot_path)  # Save the loss plot to Google Drive\n",
    "  plt.close()  # Close the plot to prevent it from displaying\n",
    "\n",
    "  # Verify learned Granger causality\n",
    "  GC_est = cdlinear.GC().cpu().data.numpy()\n",
    "\n",
    "  results_file_path = os.path.join(save_dir, f'gc_results_{i}.txt')\n",
    "  with open(results_file_path, 'w') as f:\n",
    "    f.write(f'True variable usage = {100 * np.mean(GC)}%\\n')\n",
    "    f.write(f'Estimated variable usage = {100 * np.mean(GC_est)}%\\n')\n",
    "    f.write(f'Accuracy = {100 * np.mean(GC == GC_est)}%\\n')\n",
    "    f.write(f'True positives = {np.mean(GC == 1 && GC_est == 1)}%\\n')\n",
    "    f.write(f'True negatives = {np.mean(GC == 0 && GC_est == 0)}%\\n')\n",
    "    f.write(f'False positives = {np.mean(GC == 0 && GC_est == 1)}%\\n')\n",
    "    f.write(f'False negatives = {np.mean(GC == 1 && GC_est == 0)}%\\n')\n",
    "\n",
    "  # Make figures for Granger causality matrices\n",
    "  fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
    "  axarr[0].imshow(GC, cmap='Blues')\n",
    "  axarr[0].set_title('GC actual')\n",
    "  axarr[0].set_ylabel('Affected series')\n",
    "  axarr[0].set_xlabel('Causal series')\n",
    "  axarr[0].set_xticks([])\n",
    "  axarr[0].set_yticks([])\n",
    "\n",
    "  axarr[1].imshow(GC_est, cmap='Blues', vmin=0, vmax=1, extent=(0, len(GC_est), len(GC_est), 0))\n",
    "  axarr[1].set_title('GC estimated')\n",
    "  axarr[1].set_ylabel('Affected series')\n",
    "  axarr[1].set_xlabel('Causal series')\n",
    "  axarr[1].set_xticks([])\n",
    "  axarr[1].set_yticks([])\n",
    "\n",
    "  # Mark disagreements\n",
    "  for i in range(len(GC_est)):\n",
    "    for j in range(len(GC_est)):\n",
    "        if GC[i, j] != GC_est[i, j]:\n",
    "            rect = plt.Rectangle((j, i-0.05), 1, 1, facecolor='none', edgecolor='red', linewidth=1)\n",
    "            axarr[1].add_patch(rect)\n",
    "\n",
    "  gc_plot_path = os.path.join(save_dir, f'gc_plot_{i}.png')\n",
    "  plt.savefig(gc_plot_path)  # Save the GC plot to Google Drive\n",
    "  plt.close()  # Close the plot to prevent it from displaying\n",
    "\n",
    "  # Verify lag selection\n",
    "  for i in range(len(GC_est)):\n",
    "    # Get true GC\n",
    "    GC_lag = np.zeros((5, len(GC_est)))\n",
    "    GC_lag[:3, GC[i].astype(bool)] = 1.0\n",
    "\n",
    "    # Get estimated GC\n",
    "    GC_est_lag = cdlinear.GC(ignore_lag=False, threshold=False)[i].cpu().data.numpy().T[::-1]\n",
    "\n",
    "    # Make figures for lag-based GC\n",
    "    fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    axarr[0].imshow(GC_lag, cmap='Blues', extent=(0, len(GC_est), 5, 0))\n",
    "    axarr[0].set_title(f'Series {i + 1} true GC')\n",
    "    axarr[0].set_ylabel('Lag')\n",
    "    axarr[0].set_xlabel('Series')\n",
    "    axarr[0].set_xticks(np.arange(len(GC_est)) + 0.5)\n",
    "    axarr[0].set_xticklabels(range(len(GC_est)))\n",
    "    axarr[0].set_yticks(np.arange(5) + 0.5)\n",
    "    axarr[0].set_yticklabels(range(1, 5 + 1))\n",
    "    axarr[0].tick_params(axis='both', length=0)\n",
    "\n",
    "    axarr[1].imshow(GC_est_lag, cmap='Blues', extent=(0, len(GC_est), 5, 0))\n",
    "    axarr[1].set_title(f'Series {i + 1} estimated GC')\n",
    "    axarr[1].set_ylabel('Lag')\n",
    "    axarr[1].set_xlabel('Series')\n",
    "    axarr[1].set_xticks(np.arange(len(GC_est)) + 0.5)\n",
    "    axarr[1].set_xticklabels(range(len(GC_est)))\n",
    "    axarr[1].set_yticks(np.arange(5) + 0.5)\n",
    "    axarr[1].set_yticklabels(range(1, 5 + 1))\n",
    "    axarr[1].tick_params(axis='both', length=0)\n",
    "\n",
    "    # Mark nonzeros\n",
    "    for k in range(len(GC_est)):\n",
    "        for j in range(5):\n",
    "            if GC_est_lag[j, k] > 0.0:\n",
    "                rect = plt.Rectangle((k, j), 1, 1, facecolor='none', edgecolor='green', linewidth=1.0)\n",
    "                axarr[1].add_patch(rect)\n",
    "\n",
    "    lag_gc_plot_path = os.path.join(save_dir, f'lag_gc_plot_{j}_{i}.png')\n",
    "    plt.savefig(lag_gc_plot_path)  # Save lag GC plot to Google Drive\n",
    "    plt.close()  # Close the plot to prevent it from displaying\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

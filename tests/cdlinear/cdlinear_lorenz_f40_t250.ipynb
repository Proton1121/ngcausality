{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WfZBAAJ4tcj"
      },
      "source": [
        "# cDLinear; F = 40; T = 250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhm6IGfJ445r",
        "outputId": "4979c7a2-ee43-45c1-8a31-25447f1dcaa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2ECVf6_5IV3",
        "outputId": "a9d4d977-63f5-45d8-89f7-7810fbb5573a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ngcausality'...\n",
            "remote: Enumerating objects: 215, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 215 (delta 21), reused 8 (delta 8), pack-reused 185 (from 1)\u001b[K\n",
            "Receiving objects: 100% (215/215), 2.73 MiB | 6.76 MiB/s, done.\n",
            "Resolving deltas: 100% (97/97), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://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@github.com/Proton1121/ngcausality.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avf5RXuU50ck",
        "outputId": "63e8cccf-515d-4c30-88da-e7fe0f083522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ngcausality\n"
          ]
        }
      ],
      "source": [
        "%cd /content/ngcausality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_FBbOyQ-4tcm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from data.synthetic import simulate_lorenz_96\n",
        "from data.dream import generate_causal_matrix\n",
        "from models.cdlinear import cDLinear, train_model_ista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hEbcASByB-7M"
      },
      "outputs": [],
      "source": [
        "save_dir = '/content/drive/MyDrive/ngcausality_results/' + 'loren_f40_t250/'\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kkQyyD7B4tco"
      },
      "outputs": [],
      "source": [
        "# For GPU acceleration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AFaFwK384tcp"
      },
      "outputs": [],
      "source": [
        "# Simulate data\n",
        "X_np, GC = simulate_lorenz_96(p=20, F=40, T=250)\n",
        "X = torch.tensor(X_np[np.newaxis], dtype=torch.float32, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KqL4DxxjEe84"
      },
      "outputs": [],
      "source": [
        "# Save the simulated data to Google Drive\n",
        "np.save(os.path.join(save_dir, 'X_np.npy'), X_np)  # Save X_np (simulated data)\n",
        "np.save(os.path.join(save_dir, 'GC.npy'), GC)  # Save GC (Granger causality matrix)\n",
        "\n",
        "torch.save(X, os.path.join(save_dir, 'X_tensor.pt'))\n",
        "\n",
        "with open(os.path.join(save_dir, 'data_shapes.txt'), 'w') as f:\n",
        "    f.write(f'Shape of X_np: {X_np.shape}\\n')\n",
        "    f.write(f'Shape of GC: {GC.shape}\\n')\n",
        "    f.write(f'Shape of X (torch tensor): {X.shape}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F3SH5MCp4tcr"
      },
      "outputs": [],
      "source": [
        "# Plot data\n",
        "fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
        "axarr[0].plot(X_np)\n",
        "axarr[0].set_xlabel('T')\n",
        "axarr[0].set_title('Entire time series')\n",
        "axarr[1].plot(X_np[:50])\n",
        "axarr[1].set_xlabel('T')\n",
        "axarr[1].set_title('First 50 time points')\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "# Step 5: Save the plot to Google Drive\n",
        "plot_filename = os.path.join(save_dir, 'data_plots.png')\n",
        "plt.savefig(plot_filename)  # Save the plot as a PNG file in Google Drive\n",
        "\n",
        "# Optionally, close the plot to prevent it from displaying in the notebook (you can skip this if you want to see it in the notebook)\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "njNLOBz74tcs",
        "outputId": "f4f6aec9-9d34-4707-b9c7-d577333aa8f7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "f-string: invalid syntax (<ipython-input-11-cc95d257b6bf>, line 35)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-cc95d257b6bf>\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    f.write(f'True positives = {np.sum(GC == 1 && GC_est == 1)}%\\n')\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: invalid syntax\n"
          ]
        }
      ],
      "source": [
        "for i in range(1):\n",
        "  save_dir = '/content/drive/MyDrive/ngcausality_results/' + 'loren_f40_t250/' + str(1+5*i) + '/'\n",
        "\n",
        "  if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "  #Set up model\n",
        "  cdlinear = cDLinear(X.shape[-1], hidden=100, lag=5).to(device=device)\n",
        "\n",
        "  # Train with ISTA\n",
        "  train_loss_list = train_model_ista(\n",
        "    cdlinear, X, lam=(1+5*i), lam_ridge=1e-5, lr=5e-5, penalty='H', max_iter=50000,\n",
        "    check_every=100)\n",
        "\n",
        "  # Loss function plot\n",
        "  plt.figure(figsize=(8, 5))\n",
        "  train_loss_np = [loss.cpu().detach().numpy() for loss in train_loss_list]\n",
        "  plt.plot(50 * np.arange(len(train_loss_np)), train_loss_np)\n",
        "  plt.title('cDLinear training')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Training steps')\n",
        "  plt.tight_layout()\n",
        "  loss_plot_path = os.path.join(save_dir, f'loss_plot_{1+5*i}.png')\n",
        "  plt.savefig(loss_plot_path)  # Save the loss plot to Google Drive\n",
        "  plt.close()  # Close the plot to prevent it from displaying\n",
        "\n",
        "  # Verify learned Granger causality\n",
        "  GC_est = cdlinear.GC().cpu().data.numpy()\n",
        "\n",
        "  results_file_path = os.path.join(save_dir, f'gc_results_{i}.txt')\n",
        "  with open(results_file_path, 'w') as f:\n",
        "    f.write(f'True variable usage = {100 * np.mean(GC)}%\\n')\n",
        "    f.write(f'Estimated variable usage = {100 * np.mean(GC_est)}%\\n')\n",
        "    f.write(f'Accuracy = {100 * np.mean(GC == GC_est)}%\\n')\n",
        "    f.write(f'True positives = {np.sum((GC == 1) & (GC_est == 1))}%\\n')\n",
        "    f.write(f'True negatives = {np.sum((GC == 0) & (GC_est == 0))}%\\n')\n",
        "    f.write(f'False positives = {np.sum((GC == 0) & (GC_est == 1))}%\\n')\n",
        "    f.write(f'False negatives = {np.sum((GC == 1) & (GC_est == 0))}%\\n')\n",
        "\n",
        "  # Make figures for Granger causality matrices\n",
        "  fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
        "  axarr[0].imshow(GC, cmap='Blues')\n",
        "  axarr[0].set_title('GC actual')\n",
        "  axarr[0].set_ylabel('Affected series')\n",
        "  axarr[0].set_xlabel('Causal series')\n",
        "  axarr[0].set_xticks([])\n",
        "  axarr[0].set_yticks([])\n",
        "\n",
        "  axarr[1].imshow(GC_est, cmap='Blues', vmin=0, vmax=1, extent=(0, len(GC_est), len(GC_est), 0))\n",
        "  axarr[1].set_title('GC estimated')\n",
        "  axarr[1].set_ylabel('Affected series')\n",
        "  axarr[1].set_xlabel('Causal series')\n",
        "  axarr[1].set_xticks([])\n",
        "  axarr[1].set_yticks([])\n",
        "\n",
        "  # Mark disagreements\n",
        "  for i in range(len(GC_est)):\n",
        "    for j in range(len(GC_est)):\n",
        "        if GC[i, j] != GC_est[i, j]:\n",
        "            rect = plt.Rectangle((j, i-0.05), 1, 1, facecolor='none', edgecolor='red', linewidth=1)\n",
        "            axarr[1].add_patch(rect)\n",
        "\n",
        "  gc_plot_path = os.path.join(save_dir, f'gc_plot_{i}.png')\n",
        "  plt.savefig(gc_plot_path)  # Save the GC plot to Google Drive\n",
        "  plt.close()  # Close the plot to prevent it from displaying\n",
        "\n",
        "  # Verify lag selection\n",
        "  for i in range(len(GC_est)):\n",
        "    # Get true GC\n",
        "    GC_lag = np.zeros((5, len(GC_est)))\n",
        "    GC_lag[:3, GC[i].astype(bool)] = 1.0\n",
        "\n",
        "    # Get estimated GC\n",
        "    GC_est_lag = cdlinear.GC(ignore_lag=False, threshold=False)[i].cpu().data.numpy().T[::-1]\n",
        "\n",
        "    # Make figures for lag-based GC\n",
        "    fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
        "    axarr[0].imshow(GC_lag, cmap='Blues', extent=(0, len(GC_est), 5, 0))\n",
        "    axarr[0].set_title(f'Series {i + 1} true GC')\n",
        "    axarr[0].set_ylabel('Lag')\n",
        "    axarr[0].set_xlabel('Series')\n",
        "    axarr[0].set_xticks(np.arange(len(GC_est)) + 0.5)\n",
        "    axarr[0].set_xticklabels(range(len(GC_est)))\n",
        "    axarr[0].set_yticks(np.arange(5) + 0.5)\n",
        "    axarr[0].set_yticklabels(range(1, 5 + 1))\n",
        "    axarr[0].tick_params(axis='both', length=0)\n",
        "\n",
        "    axarr[1].imshow(GC_est_lag, cmap='Blues', extent=(0, len(GC_est), 5, 0))\n",
        "    axarr[1].set_title(f'Series {i + 1} estimated GC')\n",
        "    axarr[1].set_ylabel('Lag')\n",
        "    axarr[1].set_xlabel('Series')\n",
        "    axarr[1].set_xticks(np.arange(len(GC_est)) + 0.5)\n",
        "    axarr[1].set_xticklabels(range(len(GC_est)))\n",
        "    axarr[1].set_yticks(np.arange(5) + 0.5)\n",
        "    axarr[1].set_yticklabels(range(1, 5 + 1))\n",
        "    axarr[1].tick_params(axis='both', length=0)\n",
        "\n",
        "    # Mark nonzeros\n",
        "    for k in range(len(GC_est)):\n",
        "        for j in range(5):\n",
        "            if GC_est_lag[j, k] > 0.0:\n",
        "                rect = plt.Rectangle((k, j), 1, 1, facecolor='none', edgecolor='green', linewidth=1.0)\n",
        "                axarr[1].add_patch(rect)\n",
        "\n",
        "    lag_gc_plot_path = os.path.join(save_dir, f'lag_gc_plot_{j}_{i}.png')\n",
        "    plt.savefig(lag_gc_plot_path)  # Save lag GC plot to Google Drive\n",
        "    plt.close()  # Close the plot to prevent it from displaying\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WfZBAAJ4tcj"
   },
   "source": [
    "# cGRU; F = 10; T = 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhm6IGfJ445r",
    "outputId": "bc9294f1-82e5-47e0-f477-fa55ce806b15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-2ECVf6_5IV3",
    "outputId": "20df7c3e-41d0-47b7-b6cb-a1491015371a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ngcausality'...\n",
      "remote: Enumerating objects: 240, done.\u001b[K\n",
      "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
      "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
      "remote: Total 240 (delta 39), reused 8 (delta 8), pack-reused 185 (from 1)\u001b[K\n",
      "Receiving objects: 100% (240/240), 2.77 MiB | 10.83 MiB/s, done.\n",
      "Resolving deltas: 100% (115/115), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://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@github.com/Proton1121/ngcausality.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avf5RXuU50ck",
    "outputId": "18dc04e5-6170-4557-bcaa-8fe92f4f0a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/ngcausality\n"
     ]
    }
   ],
   "source": [
    "%cd /content/ngcausality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_FBbOyQ-4tcm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data.synthetic import simulate_lorenz_96\n",
    "from data.dream import generate_causal_matrix\n",
    "from models.cdlinear import cDLinear, train_model_ista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hEbcASByB-7M"
   },
   "outputs": [],
   "source": [
    "save_dir = '/content/drive/MyDrive/ngcausality_results/' + 'cgru_lorenz_f10_t250/'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kkQyyD7B4tco"
   },
   "outputs": [],
   "source": [
    "# For GPU acceleration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AFaFwK384tcp"
   },
   "outputs": [],
   "source": [
    "# Simulate data\n",
    "X_np, GC = simulate_lorenz_96(p=20, F=10, T=250)\n",
    "X = torch.tensor(X_np[np.newaxis], dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KqL4DxxjEe84"
   },
   "outputs": [],
   "source": [
    "# Save the simulated data to Google Drive\n",
    "np.save(os.path.join(save_dir, 'X_np.npy'), X_np)  # Save X_np (simulated data)\n",
    "np.save(os.path.join(save_dir, 'GC.npy'), GC)  # Save GC (Granger causality matrix)\n",
    "\n",
    "torch.save(X, os.path.join(save_dir, 'X_tensor.pt'))\n",
    "\n",
    "with open(os.path.join(save_dir, 'data_shapes.txt'), 'w') as f:\n",
    "    f.write(f'Shape of X_np: {X_np.shape}\\n')\n",
    "    f.write(f'Shape of GC: {GC.shape}\\n')\n",
    "    f.write(f'Shape of X (torch tensor): {X.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "F3SH5MCp4tcr"
   },
   "outputs": [],
   "source": [
    "# Plot data\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
    "axarr[0].plot(X_np)\n",
    "axarr[0].set_xlabel('T')\n",
    "axarr[0].set_title('Entire time series')\n",
    "axarr[1].plot(X_np[:50])\n",
    "axarr[1].set_xlabel('T')\n",
    "axarr[1].set_title('First 50 time points')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Step 5: Save the plot to Google Drive\n",
    "plot_filename = os.path.join(save_dir, 'data_plots.png')\n",
    "plt.savefig(plot_filename)  # Save the plot as a PNG file in Google Drive\n",
    "\n",
    "# Optionally, close the plot to prevent it from displaying in the notebook (you can skip this if you want to see it in the notebook)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "njNLOBz74tcs",
    "outputId": "7443f41a-a7f3-4a7d-ceb9-acd26a1711f2"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: invalid syntax (<ipython-input-10-14c1908789b7>, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-14c1908789b7>\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    f.write(f'True positives = {np.sum(GC == 1 && GC_est == 1)}\\n')\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "  save_dir = '/content/drive/MyDrive/ngcausality_results/' + 'cgru_lorenz_f10_t250/' + str(1+5*i) + '/'\n",
    "\n",
    "  if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "  #Set up model\n",
    "  cgru = cGRU(X.shape[-1], hidden=100).to(device=device)\n",
    "\n",
    "  # Train with ISTA\n",
    "  train_model_ista(cgru, X, context=10, lr=1e-3, max_iter, lam=(1+5*i), lam_ridge=1e-2,\n",
    "                   check_every=50)\n",
    "\n",
    "  # Loss function plot\n",
    "  plt.figure(figsize=(8, 5))\n",
    "  train_loss_np = [loss.cpu().detach().numpy() for loss in train_loss_list]\n",
    "  plt.plot(50 * np.arange(len(train_loss_np)), train_loss_np)\n",
    "  plt.title('cGRU training')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Training steps')\n",
    "  plt.tight_layout()\n",
    "  loss_plot_path = os.path.join(save_dir, f'loss_plot_{1+5*i}.png')\n",
    "  plt.savefig(loss_plot_path)  # Save the loss plot to Google Drive\n",
    "  plt.close()  # Close the plot to prevent it from displaying\n",
    "\n",
    "  # Verify learned Granger causality\n",
    "  GC_est = cdlinear.GC().cpu().data.numpy()\n",
    "\n",
    "  results_file_path = os.path.join(save_dir, f'gc_results_{1+5*i}.txt')\n",
    "  with open(results_file_path, 'w') as f:\n",
    "    f.write(f'True variable usage = {100 * np.mean(GC)}%\\n')\n",
    "    f.write(f'Estimated variable usage = {100 * np.mean(GC_est)}%\\n')\n",
    "    f.write(f'Accuracy = {100 * np.mean(GC == GC_est)}%\\n')\n",
    "    f.write(f'True positives = {np.sum((GC == 1) & (GC_est == 1))}\\n')\n",
    "    f.write(f'True negatives = {np.sum((GC == 0) & (GC_est == 0))}\\n')\n",
    "    f.write(f'False positives = {np.sum((GC == 0) & (GC_est == 1))}\\n')\n",
    "    f.write(f'False negatives = {np.sum((GC == 1) & (GC_est == 0))}\\n')\n",
    "\n",
    "  # Make figures for Granger causality matrices\n",
    "  fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
    "  axarr[0].imshow(GC, cmap='Blues')\n",
    "  axarr[0].set_title('GC actual')\n",
    "  axarr[0].set_ylabel('Affected series')\n",
    "  axarr[0].set_xlabel('Causal series')\n",
    "  axarr[0].set_xticks([])\n",
    "  axarr[0].set_yticks([])\n",
    "\n",
    "  axarr[1].imshow(GC_est, cmap='Blues', vmin=0, vmax=1, extent=(0, len(GC_est), len(GC_est), 0))\n",
    "  axarr[1].set_title('GC estimated')\n",
    "  axarr[1].set_ylabel('Affected series')\n",
    "  axarr[1].set_xlabel('Causal series')\n",
    "  axarr[1].set_xticks([])\n",
    "  axarr[1].set_yticks([])\n",
    "\n",
    "  # Mark disagreements\n",
    "  for i in range(len(GC_est)):\n",
    "    for j in range(len(GC_est)):\n",
    "        if GC[i, j] != GC_est[i, j]:\n",
    "            rect = plt.Rectangle((j, i-0.05), 1, 1, facecolor='none', edgecolor='red', linewidth=1)\n",
    "            axarr[1].add_patch(rect)\n",
    "\n",
    "  gc_plot_path = os.path.join(save_dir, f'gc_plot_{i}.png')\n",
    "  plt.savefig(gc_plot_path)  # Save the GC plot to Google Drive\n",
    "  plt.close()  # Close the plot to prevent it from displaying"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WfZBAAJ4tcj"
      },
      "source": [
        "# cMamba; F = 40; T = 1000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhm6IGfJ445r",
        "outputId": "70fcd123-2b42-479d-be7b-8878cc8caca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2ECVf6_5IV3",
        "outputId": "646bf4d6-820f-4954-d008-9a30e8bfaa74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ngcausality'...\n",
            "remote: Enumerating objects: 271, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 271 (delta 62), reused 8 (delta 8), pack-reused 185 (from 1)\u001b[K\n",
            "Receiving objects: 100% (271/271), 2.80 MiB | 21.42 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://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@github.com/Proton1121/ngcausality.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avf5RXuU50ck",
        "outputId": "0d0bbcf4-9592-4160-b843-a6e6b692b0fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ngcausality\n"
          ]
        }
      ],
      "source": [
        "%cd /content/ngcausality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FBbOyQ-4tcm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from data.synthetic import simulate_lorenz_96\n",
        "from data.dream import generate_causal_matrix\n",
        "from models.cmamba import cMamba, train_model_ista, MambaConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEbcASByB-7M"
      },
      "outputs": [],
      "source": [
        "save_dir = '/content/drive/MyDrive/ngcausality_results/' + 'cmamba_lorenz_f40_t1000/'\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkQyyD7B4tco"
      },
      "outputs": [],
      "source": [
        "# For GPU acceleration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFaFwK384tcp"
      },
      "outputs": [],
      "source": [
        "# Simulate data\n",
        "X_np, GC = simulate_lorenz_96(p=20, F=40, T=1000)\n",
        "X = torch.tensor(X_np[np.newaxis], dtype=torch.float32, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqL4DxxjEe84"
      },
      "outputs": [],
      "source": [
        "# Save the simulated data to Google Drive\n",
        "np.save(os.path.join(save_dir, 'X_np.npy'), X_np)  # Save X_np (simulated data)\n",
        "np.save(os.path.join(save_dir, 'GC.npy'), GC)  # Save GC (Granger causality matrix)\n",
        "\n",
        "torch.save(X, os.path.join(save_dir, 'X_tensor.pt'))\n",
        "\n",
        "with open(os.path.join(save_dir, 'data_shapes.txt'), 'w') as f:\n",
        "    f.write(f'Shape of X_np: {X_np.shape}\\n')\n",
        "    f.write(f'Shape of GC: {GC.shape}\\n')\n",
        "    f.write(f'Shape of X (torch tensor): {X.shape}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3SH5MCp4tcr"
      },
      "outputs": [],
      "source": [
        "# Plot data\n",
        "fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
        "axarr[0].plot(X_np)\n",
        "axarr[0].set_xlabel('T')\n",
        "axarr[0].set_title('Entire time series')\n",
        "axarr[1].plot(X_np[:50])\n",
        "axarr[1].set_xlabel('T')\n",
        "axarr[1].set_title('First 50 time points')\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "# Step 5: Save the plot to Google Drive\n",
        "plot_filename = os.path.join(save_dir, 'data_plots.png')\n",
        "plt.savefig(plot_filename)  # Save the plot as a PNG file in Google Drive\n",
        "\n",
        "# Optionally, close the plot to prevent it from displaying in the notebook (you can skip this if you want to see it in the notebook)\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "njNLOBz74tcs",
        "outputId": "782e034f-0359-43d8-d4f1-75722e5b5561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------Iter = 50----------\n",
            "Loss = 210.216476\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 100----------\n",
            "Loss = 194.485703\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 150----------\n",
            "Loss = 186.728012\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 200----------\n",
            "Loss = 181.733658\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 250----------\n",
            "Loss = 178.046234\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 300----------\n",
            "Loss = 175.074554\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 350----------\n",
            "Loss = 172.530487\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 400----------\n",
            "Loss = 170.256577\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 450----------\n",
            "Loss = 168.161484\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 500----------\n",
            "Loss = 166.190659\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 550----------\n",
            "Loss = 164.311111\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 600----------\n",
            "Loss = 162.503036\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 650----------\n",
            "Loss = 160.754700\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 700----------\n",
            "Loss = 159.058517\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 750----------\n",
            "Loss = 157.408676\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 800----------\n",
            "Loss = 155.799637\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 850----------\n",
            "Loss = 154.226318\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 900----------\n",
            "Loss = 152.685440\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 950----------\n",
            "Loss = 151.174973\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1000----------\n",
            "Loss = 149.693420\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1050----------\n",
            "Loss = 148.239792\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1100----------\n",
            "Loss = 146.813889\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1150----------\n",
            "Loss = 145.415833\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1200----------\n",
            "Loss = 144.045761\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1250----------\n",
            "Loss = 142.703232\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1300----------\n",
            "Loss = 141.387253\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1350----------\n",
            "Loss = 140.096405\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1400----------\n",
            "Loss = 138.829224\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1450----------\n",
            "Loss = 137.584274\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1500----------\n",
            "Loss = 136.360199\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1550----------\n",
            "Loss = 135.156143\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1600----------\n",
            "Loss = 133.972122\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1650----------\n",
            "Loss = 132.809128\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1700----------\n",
            "Loss = 131.668015\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1750----------\n",
            "Loss = 130.549072\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1800----------\n",
            "Loss = 129.451767\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1850----------\n",
            "Loss = 128.375198\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1900----------\n",
            "Loss = 127.318199\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1950----------\n",
            "Loss = 126.279495\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2000----------\n",
            "Loss = 125.258034\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2050----------\n",
            "Loss = 124.252831\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2100----------\n",
            "Loss = 123.263115\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2150----------\n",
            "Loss = 122.288223\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2200----------\n",
            "Loss = 121.327675\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2250----------\n",
            "Loss = 120.381096\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2300----------\n",
            "Loss = 119.448318\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2350----------\n",
            "Loss = 118.529167\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2400----------\n",
            "Loss = 117.623535\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2450----------\n",
            "Loss = 116.731339\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2500----------\n",
            "Loss = 115.852501\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2550----------\n",
            "Loss = 114.986954\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2600----------\n",
            "Loss = 114.134499\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2650----------\n",
            "Loss = 113.294975\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2700----------\n",
            "Loss = 112.468056\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2750----------\n",
            "Loss = 111.653503\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2800----------\n",
            "Loss = 110.851051\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2850----------\n",
            "Loss = 110.060486\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2900----------\n",
            "Loss = 109.281670\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2950----------\n",
            "Loss = 108.514404\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3000----------\n",
            "Loss = 107.758583\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3050----------\n",
            "Loss = 107.014053\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3100----------\n",
            "Loss = 106.280663\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3150----------\n",
            "Loss = 105.558311\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3200----------\n",
            "Loss = 104.846817\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3250----------\n",
            "Loss = 104.146080\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3300----------\n",
            "Loss = 103.455887\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3350----------\n",
            "Loss = 102.776077\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3400----------\n",
            "Loss = 102.106499\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3450----------\n",
            "Loss = 101.447006\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3500----------\n",
            "Loss = 100.797447\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3550----------\n",
            "Loss = 100.157700\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3600----------\n",
            "Loss = 99.527672\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3650----------\n",
            "Loss = 98.907265\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3700----------\n",
            "Loss = 98.296364\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3750----------\n",
            "Loss = 97.694847\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3800----------\n",
            "Loss = 97.102592\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3850----------\n",
            "Loss = 96.519417\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3900----------\n",
            "Loss = 95.945183\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3950----------\n",
            "Loss = 95.379692\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4000----------\n",
            "Loss = 94.822807\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4050----------\n",
            "Loss = 94.274330\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4100----------\n",
            "Loss = 93.734085\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4150----------\n",
            "Loss = 93.201897\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4200----------\n",
            "Loss = 92.677589\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4250----------\n",
            "Loss = 92.161003\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4300----------\n",
            "Loss = 91.651962\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4350----------\n",
            "Loss = 91.150291\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4400----------\n",
            "Loss = 90.655846\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4450----------\n",
            "Loss = 90.168480\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4500----------\n",
            "Loss = 89.688026\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4550----------\n",
            "Loss = 89.214348\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4600----------\n",
            "Loss = 88.747307\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4650----------\n",
            "Loss = 88.286736\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4700----------\n",
            "Loss = 87.832512\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4750----------\n",
            "Loss = 87.384499\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4800----------\n",
            "Loss = 86.942528\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4850----------\n",
            "Loss = 86.506485\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4900----------\n",
            "Loss = 86.076218\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4950----------\n",
            "Loss = 85.651588\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5000----------\n",
            "Loss = 85.232460\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5050----------\n",
            "Loss = 84.818680\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5100----------\n",
            "Loss = 84.410118\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5150----------\n",
            "Loss = 84.006622\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5200----------\n",
            "Loss = 83.608032\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5250----------\n",
            "Loss = 83.214218\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5300----------\n",
            "Loss = 82.825035\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5350----------\n",
            "Loss = 82.440414\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5400----------\n",
            "Loss = 82.060204\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5450----------\n",
            "Loss = 81.684441\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5500----------\n",
            "Loss = 81.313095\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5550----------\n",
            "Loss = 80.946251\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5600----------\n",
            "Loss = 80.583923\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5650----------\n",
            "Loss = 80.226143\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5700----------\n",
            "Loss = 79.872864\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5750----------\n",
            "Loss = 79.524086\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5800----------\n",
            "Loss = 79.179733\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5850----------\n",
            "Loss = 78.839745\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5900----------\n",
            "Loss = 78.504021\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5950----------\n",
            "Loss = 78.172493\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6000----------\n",
            "Loss = 77.845062\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6050----------\n",
            "Loss = 77.521652\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6100----------\n",
            "Loss = 77.202133\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6150----------\n",
            "Loss = 76.886452\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6200----------\n",
            "Loss = 76.574532\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6250----------\n",
            "Loss = 76.266289\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6300----------\n",
            "Loss = 75.961678\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6350----------\n",
            "Loss = 75.660637\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6400----------\n",
            "Loss = 75.363091\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6450----------\n",
            "Loss = 75.068985\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6500----------\n",
            "Loss = 74.778252\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6550----------\n",
            "Loss = 74.490845\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6600----------\n",
            "Loss = 74.206688\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6650----------\n",
            "Loss = 73.925735\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6700----------\n",
            "Loss = 73.647911\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6750----------\n",
            "Loss = 73.373169\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6800----------\n",
            "Loss = 73.101440\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6850----------\n",
            "Loss = 72.832687\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6900----------\n",
            "Loss = 72.566818\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6950----------\n",
            "Loss = 72.303802\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7000----------\n",
            "Loss = 72.043571\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7050----------\n",
            "Loss = 71.786072\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7100----------\n",
            "Loss = 71.531250\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7150----------\n",
            "Loss = 71.279068\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7200----------\n",
            "Loss = 71.029442\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7250----------\n",
            "Loss = 70.782356\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7300----------\n",
            "Loss = 70.537758\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7350----------\n",
            "Loss = 70.295609\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7400----------\n",
            "Loss = 70.055855\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7450----------\n",
            "Loss = 69.818481\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7500----------\n",
            "Loss = 69.583435\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7550----------\n",
            "Loss = 69.350693\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7600----------\n",
            "Loss = 69.120201\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7650----------\n",
            "Loss = 68.891960\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7700----------\n",
            "Loss = 68.665901\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7750----------\n",
            "Loss = 68.442009\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7800----------\n",
            "Loss = 68.220253\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7850----------\n",
            "Loss = 68.000618\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7900----------\n",
            "Loss = 67.783043\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7950----------\n",
            "Loss = 67.567528\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8000----------\n",
            "Loss = 67.354027\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8050----------\n",
            "Loss = 67.142540\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8100----------\n",
            "Loss = 66.933022\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8150----------\n",
            "Loss = 66.725456\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8200----------\n",
            "Loss = 66.519798\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8250----------\n",
            "Loss = 66.316063\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8300----------\n",
            "Loss = 66.114197\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8350----------\n",
            "Loss = 65.914185\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8400----------\n",
            "Loss = 65.716026\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8450----------\n",
            "Loss = 65.519669\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8500----------\n",
            "Loss = 65.325096\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8550----------\n",
            "Loss = 65.132309\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8600----------\n",
            "Loss = 64.941254\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8650----------\n",
            "Loss = 64.751945\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8700----------\n",
            "Loss = 64.564331\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8750----------\n",
            "Loss = 64.378410\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8800----------\n",
            "Loss = 64.194176\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8850----------\n",
            "Loss = 64.011574\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8900----------\n",
            "Loss = 63.830627\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 8950----------\n",
            "Loss = 63.651295\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9000----------\n",
            "Loss = 63.473572\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9050----------\n",
            "Loss = 63.297432\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9100----------\n",
            "Loss = 63.122860\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9150----------\n",
            "Loss = 62.949841\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9200----------\n",
            "Loss = 62.778370\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9250----------\n",
            "Loss = 62.608418\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9300----------\n",
            "Loss = 62.439980\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9350----------\n",
            "Loss = 62.273022\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9400----------\n",
            "Loss = 62.107544\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9450----------\n",
            "Loss = 61.943531\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9500----------\n",
            "Loss = 61.780972\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9550----------\n",
            "Loss = 61.619820\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9600----------\n",
            "Loss = 61.460091\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9650----------\n",
            "Loss = 61.301758\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9700----------\n",
            "Loss = 61.144806\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9750----------\n",
            "Loss = 60.989204\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9800----------\n",
            "Loss = 60.834961\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9850----------\n",
            "Loss = 60.682034\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9900----------\n",
            "Loss = 60.530407\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 9950----------\n",
            "Loss = 60.380085\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10000----------\n",
            "Loss = 60.231030\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10050----------\n",
            "Loss = 60.083248\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10100----------\n",
            "Loss = 59.936676\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10150----------\n",
            "Loss = 59.791340\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10200----------\n",
            "Loss = 59.647198\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10250----------\n",
            "Loss = 59.504242\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10300----------\n",
            "Loss = 59.362453\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10350----------\n",
            "Loss = 59.221813\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10400----------\n",
            "Loss = 59.082314\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10450----------\n",
            "Loss = 58.943916\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10500----------\n",
            "Loss = 58.806629\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10550----------\n",
            "Loss = 58.670418\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10600----------\n",
            "Loss = 58.535286\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10650----------\n",
            "Loss = 58.401196\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10700----------\n",
            "Loss = 58.268147\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10750----------\n",
            "Loss = 58.136120\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10800----------\n",
            "Loss = 58.005104\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10850----------\n",
            "Loss = 57.875072\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10900----------\n",
            "Loss = 57.746033\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 10950----------\n",
            "Loss = 57.617958\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11000----------\n",
            "Loss = 57.490826\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11050----------\n",
            "Loss = 57.364643\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11100----------\n",
            "Loss = 57.239380\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11150----------\n",
            "Loss = 57.115028\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11200----------\n",
            "Loss = 56.991589\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11250----------\n",
            "Loss = 56.869026\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11300----------\n",
            "Loss = 56.747353\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11350----------\n",
            "Loss = 56.626537\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11400----------\n",
            "Loss = 56.506580\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11450----------\n",
            "Loss = 56.387470\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11500----------\n",
            "Loss = 56.269192\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11550----------\n",
            "Loss = 56.151730\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11600----------\n",
            "Loss = 56.035091\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11650----------\n",
            "Loss = 55.919247\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11700----------\n",
            "Loss = 55.804199\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11750----------\n",
            "Loss = 55.689930\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11800----------\n",
            "Loss = 55.576443\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11850----------\n",
            "Loss = 55.463715\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11900----------\n",
            "Loss = 55.351753\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 11950----------\n",
            "Loss = 55.240536\n",
            "Variable usage = 100.00%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2db5833c8da3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# Train with ISTA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   train_loss_list=train_model_ista(cmamba, X, context=10, lr=1e-5, max_iter=20000, lam=(1+5*i), lam_ridge=1e-4,\n\u001b[0m\u001b[1;32m     14\u001b[0m                    check_every=50)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ngcausality/models/cmamba.py\u001b[0m in \u001b[0;36mtrain_model_ista\u001b[0;34m(cmamba, X, context, lr, max_iter, lam, lam_ridge, lookback, check_every, verbose)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;31m# Take gradient step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0msmooth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcmamba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i in range(20):\n",
        "  save_dir = '/content/drive/MyDrive/ngcausality_results/' + 'cmamba_lorenz_f40_t1000/lam=' + str(1+5*i) + '/'\n",
        "\n",
        "  if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "  #cMamba config\n",
        "  cmamba_config = MambaConfig(d_model=20)\n",
        "  #Set up model\n",
        "  cmamba = cMamba(cmamba_config).to(device=device)\n",
        "\n",
        "  # Train with ISTA\n",
        "  train_loss_list=train_model_ista(cmamba, X, context=10, lr=5e-6, max_iter=20000, lam=(1+5*i), lam_ridge=1e-5,\n",
        "                   check_every=50)\n",
        "\n",
        "  # Loss function plot\n",
        "  plt.figure(figsize=(8, 5))\n",
        "  train_loss_np = [loss.cpu().detach().numpy() for loss in train_loss_list]\n",
        "  plt.plot(50 * np.arange(len(train_loss_np)), train_loss_np)\n",
        "  plt.title('cMamba training')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Training steps')\n",
        "  plt.tight_layout()\n",
        "  loss_plot_path = os.path.join(save_dir, f'loss_plot_{1+5*i}.png')\n",
        "  plt.savefig(loss_plot_path)  # Save the loss plot to Google Drive\n",
        "  plt.close()  # Close the plot to prevent it from displaying\n",
        "\n",
        "  # Verify learned Granger causality\n",
        "  GC_est = cgru.GC().cpu().data.numpy()\n",
        "\n",
        "  results_file_path = os.path.join(save_dir, f'gc_results_{1+5*i}.txt')\n",
        "  with open(results_file_path, 'w') as f:\n",
        "    f.write(f'True variable usage = {100 * np.mean(GC)}%\\n')\n",
        "    f.write(f'Estimated variable usage = {100 * np.mean(GC_est)}%\\n')\n",
        "    f.write(f'Accuracy = {100 * np.mean(GC == GC_est)}%\\n')\n",
        "    f.write(f'True positives = {np.sum((GC == 1) & (GC_est == 1))}\\n')\n",
        "    f.write(f'True negatives = {np.sum((GC == 0) & (GC_est == 0))}\\n')\n",
        "    f.write(f'False positives = {np.sum((GC == 0) & (GC_est == 1))}\\n')\n",
        "    f.write(f'False negatives = {np.sum((GC == 1) & (GC_est == 0))}\\n')\n",
        "\n",
        "  # Make figures for Granger causality matrices\n",
        "  fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
        "  axarr[0].imshow(GC, cmap='Blues')\n",
        "  axarr[0].set_title('GC actual')\n",
        "  axarr[0].set_ylabel('Affected series')\n",
        "  axarr[0].set_xlabel('Causal series')\n",
        "  axarr[0].set_xticks([])\n",
        "  axarr[0].set_yticks([])\n",
        "\n",
        "  axarr[1].imshow(GC_est, cmap='Blues', vmin=0, vmax=1, extent=(0, len(GC_est), len(GC_est), 0))\n",
        "  axarr[1].set_title('GC estimated')\n",
        "  axarr[1].set_ylabel('Affected series')\n",
        "  axarr[1].set_xlabel('Causal series')\n",
        "  axarr[1].set_xticks([])\n",
        "  axarr[1].set_yticks([])\n",
        "\n",
        "  # Mark disagreements\n",
        "  for i in range(len(GC_est)):\n",
        "    for j in range(len(GC_est)):\n",
        "        if GC[i, j] != GC_est[i, j]:\n",
        "            rect = plt.Rectangle((j, i-0.05), 1, 1, facecolor='none', edgecolor='red', linewidth=1)\n",
        "            axarr[1].add_patch(rect)\n",
        "\n",
        "  gc_plot_path = os.path.join(save_dir, f'gc_plot_{i}.png')\n",
        "  plt.savefig(gc_plot_path)  # Save the GC plot to Google Drive\n",
        "  plt.close()  # Close the plot to prevent it from displaying"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
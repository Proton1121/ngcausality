{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WfZBAAJ4tcj"
      },
      "source": [
        "# cMLP; F = 40; T = 1000; Layers = 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhm6IGfJ445r",
        "outputId": "949669d3-91c3-4900-973c-5fa44b9d6b1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2ECVf6_5IV3",
        "outputId": "d85615d2-0ed7-4bee-dd62-9217fa88b2ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ngcausality'...\n",
            "remote: Enumerating objects: 220, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 220 (delta 25), reused 8 (delta 8), pack-reused 185 (from 1)\u001b[K\n",
            "Receiving objects: 100% (220/220), 2.74 MiB | 27.21 MiB/s, done.\n",
            "Resolving deltas: 100% (101/101), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://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@github.com/Proton1121/ngcausality.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avf5RXuU50ck",
        "outputId": "c69fcca5-9338-42cd-9532-a71c4eab9ade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ngcausality\n"
          ]
        }
      ],
      "source": [
        "%cd /content/ngcausality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FBbOyQ-4tcm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from data.synthetic import simulate_lorenz_96\n",
        "from data.dream import generate_causal_matrix\n",
        "from models.cmlp import cMLP, train_model_ista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEbcASByB-7M"
      },
      "outputs": [],
      "source": [
        "save_dir = '/content/drive/MyDrive/ngcausality_results/' + 'loren_f40_t1000_layer5/'\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkQyyD7B4tco"
      },
      "outputs": [],
      "source": [
        "# For GPU acceleration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFaFwK384tcp"
      },
      "outputs": [],
      "source": [
        "# Simulate data\n",
        "X_np, GC = simulate_lorenz_96(p=20, F=40, T=1000)\n",
        "X = torch.tensor(X_np[np.newaxis], dtype=torch.float32, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqL4DxxjEe84"
      },
      "outputs": [],
      "source": [
        "# Save the simulated data to Google Drive\n",
        "np.save(os.path.join(save_dir, 'X_np.npy'), X_np)  # Save X_np (simulated data)\n",
        "np.save(os.path.join(save_dir, 'GC.npy'), GC)  # Save GC (Granger causality matrix)\n",
        "\n",
        "torch.save(X, os.path.join(save_dir, 'X_tensor.pt'))\n",
        "\n",
        "with open(os.path.join(save_dir, 'data_shapes.txt'), 'w') as f:\n",
        "    f.write(f'Shape of X_np: {X_np.shape}\\n')\n",
        "    f.write(f'Shape of GC: {GC.shape}\\n')\n",
        "    f.write(f'Shape of X (torch tensor): {X.shape}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3SH5MCp4tcr"
      },
      "outputs": [],
      "source": [
        "# Plot data\n",
        "fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
        "axarr[0].plot(X_np)\n",
        "axarr[0].set_xlabel('T')\n",
        "axarr[0].set_title('Entire time series')\n",
        "axarr[1].plot(X_np[:50])\n",
        "axarr[1].set_xlabel('T')\n",
        "axarr[1].set_title('First 50 time points')\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "# Step 5: Save the plot to Google Drive\n",
        "plot_filename = os.path.join(save_dir, 'data_plots.png')\n",
        "plt.savefig(plot_filename)  # Save the plot as a PNG file in Google Drive\n",
        "\n",
        "# Optionally, close the plot to prevent it from displaying in the notebook (you can skip this if you want to see it in the notebook)\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "njNLOBz74tcs",
        "outputId": "c8dded4f-e664-4e6e-c299-92c5846c306b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------Iter = 100----------\n",
            "Loss = 204.551559\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 200----------\n",
            "Loss = 202.003098\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 300----------\n",
            "Loss = 199.387512\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 400----------\n",
            "Loss = 196.657669\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 500----------\n",
            "Loss = 194.027924\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 600----------\n",
            "Loss = 191.308945\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 700----------\n",
            "Loss = 188.128464\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 800----------\n",
            "Loss = 184.263504\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 900----------\n",
            "Loss = 179.983978\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1000----------\n",
            "Loss = 176.134491\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1100----------\n",
            "Loss = 172.631134\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1200----------\n",
            "Loss = 169.210434\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1300----------\n",
            "Loss = 165.697876\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1400----------\n",
            "Loss = 161.864151\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1500----------\n",
            "Loss = 157.835693\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1600----------\n",
            "Loss = 153.415878\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1700----------\n",
            "Loss = 149.076080\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1800----------\n",
            "Loss = 144.792328\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1900----------\n",
            "Loss = 140.776169\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2000----------\n",
            "Loss = 136.814575\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2100----------\n",
            "Loss = 133.008331\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2200----------\n",
            "Loss = 129.445053\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2300----------\n",
            "Loss = 126.328003\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2400----------\n",
            "Loss = 122.701561\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2500----------\n",
            "Loss = 119.548096\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2600----------\n",
            "Loss = 116.685745\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2700----------\n",
            "Loss = 113.201248\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2800----------\n",
            "Loss = 109.878716\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2900----------\n",
            "Loss = 107.688316\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3000----------\n",
            "Loss = 105.429771\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3100----------\n",
            "Loss = 101.973633\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3200----------\n",
            "Loss = 100.181061\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3300----------\n",
            "Loss = 98.151787\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3400----------\n",
            "Loss = 96.233246\n",
            "Variable usage = 99.75%\n",
            "----------Iter = 3500----------\n",
            "Loss = 94.444702\n",
            "Variable usage = 99.75%\n",
            "----------Iter = 3600----------\n",
            "Loss = 91.457703\n",
            "Variable usage = 99.50%\n",
            "----------Iter = 3700----------\n",
            "Loss = 91.066154\n",
            "Variable usage = 99.50%\n",
            "----------Iter = 3800----------\n",
            "Loss = 88.173515\n",
            "Variable usage = 99.25%\n",
            "----------Iter = 3900----------\n",
            "Loss = 87.850082\n",
            "Variable usage = 99.25%\n",
            "----------Iter = 4000----------\n",
            "Loss = 85.894897\n",
            "Variable usage = 98.75%\n",
            "----------Iter = 4100----------\n",
            "Loss = 84.336929\n",
            "Variable usage = 98.75%\n",
            "----------Iter = 4200----------\n",
            "Loss = 86.116722\n",
            "Variable usage = 98.75%\n",
            "----------Iter = 4300----------\n",
            "Loss = 83.021973\n",
            "Variable usage = 98.00%\n",
            "----------Iter = 4400----------\n",
            "Loss = 81.766388\n",
            "Variable usage = 97.50%\n",
            "----------Iter = 4500----------\n",
            "Loss = 81.487259\n",
            "Variable usage = 97.00%\n",
            "----------Iter = 4600----------\n",
            "Loss = 79.256187\n",
            "Variable usage = 96.75%\n",
            "----------Iter = 4700----------\n",
            "Loss = 77.531563\n",
            "Variable usage = 96.50%\n",
            "----------Iter = 4800----------\n",
            "Loss = 78.065666\n",
            "Variable usage = 96.00%\n",
            "----------Iter = 4900----------\n",
            "Loss = 75.007851\n",
            "Variable usage = 95.75%\n",
            "----------Iter = 5000----------\n",
            "Loss = 74.386803\n",
            "Variable usage = 95.50%\n",
            "----------Iter = 5100----------\n",
            "Loss = 71.891167\n",
            "Variable usage = 95.50%\n",
            "----------Iter = 5200----------\n",
            "Loss = 72.369080\n",
            "Variable usage = 95.50%\n",
            "----------Iter = 5300----------\n",
            "Loss = 71.552345\n",
            "Variable usage = 95.50%\n",
            "----------Iter = 5400----------\n",
            "Loss = 70.857399\n",
            "Variable usage = 95.75%\n",
            "----------Iter = 5500----------\n",
            "Loss = 73.823570\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 5600----------\n",
            "Loss = 68.614738\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 5700----------\n",
            "Loss = 68.871025\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 5800----------\n",
            "Loss = 67.816490\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 5900----------\n",
            "Loss = 67.164162\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 6000----------\n",
            "Loss = 67.266510\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 6100----------\n",
            "Loss = 66.717583\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 6200----------\n",
            "Loss = 64.023064\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 6300----------\n",
            "Loss = 64.879082\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 6400----------\n",
            "Loss = 64.529716\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 6500----------\n",
            "Loss = 63.850933\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 6600----------\n",
            "Loss = 66.170448\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 6700----------\n",
            "Loss = 63.044933\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 6800----------\n",
            "Loss = 61.142494\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 6900----------\n",
            "Loss = 64.873589\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 7000----------\n",
            "Loss = 63.596565\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 7100----------\n",
            "Loss = 62.318684\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 7200----------\n",
            "Loss = 59.815990\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 7300----------\n",
            "Loss = 59.951973\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 7400----------\n",
            "Loss = 60.676094\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 7500----------\n",
            "Loss = 59.316628\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 7600----------\n",
            "Loss = 58.275002\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 7700----------\n",
            "Loss = 58.555420\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 7800----------\n",
            "Loss = 59.535633\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 7900----------\n",
            "Loss = 59.364906\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 8000----------\n",
            "Loss = 60.492031\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 8100----------\n",
            "Loss = 56.670265\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 8200----------\n",
            "Loss = 55.961201\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 8300----------\n",
            "Loss = 57.739571\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 8400----------\n",
            "Loss = 55.374935\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 8500----------\n",
            "Loss = 55.377804\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 8600----------\n",
            "Loss = 56.004391\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 8700----------\n",
            "Loss = 55.358459\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 8800----------\n",
            "Loss = 52.338409\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 8900----------\n",
            "Loss = 55.734913\n",
            "Variable usage = 95.25%\n",
            "----------Iter = 9000----------\n",
            "Loss = 55.672863\n",
            "Variable usage = 95.50%\n",
            "----------Iter = 9100----------\n",
            "Loss = 53.883240\n",
            "Variable usage = 95.50%\n",
            "----------Iter = 9200----------\n",
            "Loss = 56.186749\n",
            "Variable usage = 95.50%\n",
            "----------Iter = 9300----------\n",
            "Loss = 53.563904\n",
            "Variable usage = 95.50%\n",
            "Stopping early\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'cdlinear' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-625ca1b5d8ee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;31m# Verify learned Granger causality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0mGC_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcdlinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0mresults_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'gc_results_{i}.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cdlinear' is not defined"
          ]
        }
      ],
      "source": [
        "for i in range(20):\n",
        "  save_dir = '/content/drive/MyDrive/ngcausality_results/' + 'loren_f40_t1000_layer5/lam=' + str(1+i) + '/'\n",
        "\n",
        "  if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "  #Set up model\n",
        "  cmlp = cMLP(X.shape[-1], hidden=[10,10,10,10,10], lag=5).to(device=device)\n",
        "\n",
        "  # Train with ISTA\n",
        "  train_loss_list = train_model_ista(\n",
        "    cmlp, X, lam=(1+i), lam_ridge=1e-6, lr=1e-5, penalty='H', max_iter=50000,\n",
        "    check_every=100)\n",
        "\n",
        "  # Loss function plot\n",
        "  plt.figure(figsize=(8, 5))\n",
        "  train_loss_np = [loss.cpu().detach().numpy() for loss in train_loss_list]\n",
        "  plt.plot(50 * np.arange(len(train_loss_np)), train_loss_np)\n",
        "  plt.title('cMLP training')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Training steps')\n",
        "  plt.tight_layout()\n",
        "  loss_plot_path = os.path.join(save_dir, f'loss_plot_{1+i}.png')\n",
        "  plt.savefig(loss_plot_path)  # Save the loss plot to Google Drive\n",
        "  plt.close()  # Close the plot to prevent it from displaying\n",
        "\n",
        "  # Verify learned Granger causality\n",
        "  GC_est = cmlp.GC().cpu().data.numpy()\n",
        "\n",
        "  results_file_path = os.path.join(save_dir, f'gc_results_{i}.txt')\n",
        "  with open(results_file_path, 'w') as f:\n",
        "    f.write(f'True variable usage = {100 * np.mean(GC)}%\\n')\n",
        "    f.write(f'Estimated variable usage = {100 * np.mean(GC_est)}%\\n')\n",
        "    f.write(f'Accuracy = {100 * np.mean(GC == GC_est)}%\\n')\n",
        "    f.write(f'True positives = {np.sum((GC == 1) & (GC_est == 1))}\\n')\n",
        "    f.write(f'True negatives = {np.sum((GC == 0) & (GC_est == 0))}\\n')\n",
        "    f.write(f'False positives = {np.sum((GC == 0) & (GC_est == 1))}\\n')\n",
        "    f.write(f'False negatives = {np.sum((GC == 1) & (GC_est == 0))}\\n')\n",
        "\n",
        "  # Make figures for Granger causality matrices\n",
        "  fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
        "  axarr[0].imshow(GC, cmap='Blues')\n",
        "  axarr[0].set_title('GC actual')\n",
        "  axarr[0].set_ylabel('Affected series')\n",
        "  axarr[0].set_xlabel('Causal series')\n",
        "  axarr[0].set_xticks([])\n",
        "  axarr[0].set_yticks([])\n",
        "\n",
        "  axarr[1].imshow(GC_est, cmap='Blues', vmin=0, vmax=1, extent=(0, len(GC_est), len(GC_est), 0))\n",
        "  axarr[1].set_title('GC estimated')\n",
        "  axarr[1].set_ylabel('Affected series')\n",
        "  axarr[1].set_xlabel('Causal series')\n",
        "  axarr[1].set_xticks([])\n",
        "  axarr[1].set_yticks([])\n",
        "\n",
        "  # Mark disagreements\n",
        "  for i in range(len(GC_est)):\n",
        "    for j in range(len(GC_est)):\n",
        "        if GC[i, j] != GC_est[i, j]:\n",
        "            rect = plt.Rectangle((j, i-0.05), 1, 1, facecolor='none', edgecolor='red', linewidth=1)\n",
        "            axarr[1].add_patch(rect)\n",
        "\n",
        "  gc_plot_path = os.path.join(save_dir, f'gc_plot_{i}.png')\n",
        "  plt.savefig(gc_plot_path)  # Save the GC plot to Google Drive\n",
        "  plt.close()  # Close the plot to prevent it from displaying\n",
        "\n",
        "  # Verify lag selection\n",
        "  for i in range(len(GC_est)):\n",
        "    # Get true GC\n",
        "    GC_lag = np.zeros((5, len(GC_est)))\n",
        "    GC_lag[:3, GC[i].astype(bool)] = 1.0\n",
        "\n",
        "    # Get estimated GC\n",
        "    GC_est_lag = cmlp.GC(ignore_lag=False, threshold=False)[i].cpu().data.numpy().T[::-1]\n",
        "\n",
        "    # Make figures for lag-based GC\n",
        "    fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
        "    axarr[0].imshow(GC_lag, cmap='Blues', extent=(0, len(GC_est), 5, 0))\n",
        "    axarr[0].set_title(f'Series {i + 1} true GC')\n",
        "    axarr[0].set_ylabel('Lag')\n",
        "    axarr[0].set_xlabel('Series')\n",
        "    axarr[0].set_xticks(np.arange(len(GC_est)) + 0.5)\n",
        "    axarr[0].set_xticklabels(range(len(GC_est)))\n",
        "    axarr[0].set_yticks(np.arange(5) + 0.5)\n",
        "    axarr[0].set_yticklabels(range(1, 5 + 1))\n",
        "    axarr[0].tick_params(axis='both', length=0)\n",
        "\n",
        "    axarr[1].imshow(GC_est_lag, cmap='Blues', extent=(0, len(GC_est), 5, 0))\n",
        "    axarr[1].set_title(f'Series {i + 1} estimated GC')\n",
        "    axarr[1].set_ylabel('Lag')\n",
        "    axarr[1].set_xlabel('Series')\n",
        "    axarr[1].set_xticks(np.arange(len(GC_est)) + 0.5)\n",
        "    axarr[1].set_xticklabels(range(len(GC_est)))\n",
        "    axarr[1].set_yticks(np.arange(5) + 0.5)\n",
        "    axarr[1].set_yticklabels(range(1, 5 + 1))\n",
        "    axarr[1].tick_params(axis='both', length=0)\n",
        "\n",
        "    # Mark nonzeros\n",
        "    for k in range(len(GC_est)):\n",
        "        for j in range(5):\n",
        "            if GC_est_lag[j, k] > 0.0:\n",
        "                rect = plt.Rectangle((k, j), 1, 1, facecolor='none', edgecolor='green', linewidth=1.0)\n",
        "                axarr[1].add_patch(rect)\n",
        "\n",
        "    lag_gc_plot_path = os.path.join(save_dir, f'lag_gc_plot_{j}_{i}.png')\n",
        "    plt.savefig(lag_gc_plot_path)  # Save lag GC plot to Google Drive\n",
        "    plt.close()  # Close the plot to prevent it from displaying\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
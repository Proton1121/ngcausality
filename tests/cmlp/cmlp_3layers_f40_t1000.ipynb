{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WfZBAAJ4tcj"
      },
      "source": [
        "# cMLP; F = 40; T = 1000; Layers = 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhm6IGfJ445r",
        "outputId": "949669d3-91c3-4900-973c-5fa44b9d6b1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2ECVf6_5IV3",
        "outputId": "d85615d2-0ed7-4bee-dd62-9217fa88b2ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ngcausality'...\n",
            "remote: Enumerating objects: 220, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 220 (delta 25), reused 8 (delta 8), pack-reused 185 (from 1)\u001b[K\n",
            "Receiving objects: 100% (220/220), 2.74 MiB | 27.21 MiB/s, done.\n",
            "Resolving deltas: 100% (101/101), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://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@github.com/Proton1121/ngcausality.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avf5RXuU50ck",
        "outputId": "c69fcca5-9338-42cd-9532-a71c4eab9ade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ngcausality\n"
          ]
        }
      ],
      "source": [
        "%cd /content/ngcausality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FBbOyQ-4tcm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from data.synthetic import simulate_lorenz_96\n",
        "from data.dream import generate_causal_matrix\n",
        "from models.cmlp import cMLP, train_model_ista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEbcASByB-7M"
      },
      "outputs": [],
      "source": [
        "save_dir = '/content/drive/MyDrive/ngcausality_results/' + 'loren_f40_t1000_layer3/'\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkQyyD7B4tco"
      },
      "outputs": [],
      "source": [
        "# For GPU acceleration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFaFwK384tcp"
      },
      "outputs": [],
      "source": [
        "# Simulate data\n",
        "X_np, GC = simulate_lorenz_96(p=20, F=40, T=1000)\n",
        "X = torch.tensor(X_np[np.newaxis], dtype=torch.float32, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqL4DxxjEe84"
      },
      "outputs": [],
      "source": [
        "# Save the simulated data to Google Drive\n",
        "np.save(os.path.join(save_dir, 'X_np.npy'), X_np)  # Save X_np (simulated data)\n",
        "np.save(os.path.join(save_dir, 'GC.npy'), GC)  # Save GC (Granger causality matrix)\n",
        "\n",
        "torch.save(X, os.path.join(save_dir, 'X_tensor.pt'))\n",
        "\n",
        "with open(os.path.join(save_dir, 'data_shapes.txt'), 'w') as f:\n",
        "    f.write(f'Shape of X_np: {X_np.shape}\\n')\n",
        "    f.write(f'Shape of GC: {GC.shape}\\n')\n",
        "    f.write(f'Shape of X (torch tensor): {X.shape}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3SH5MCp4tcr"
      },
      "outputs": [],
      "source": [
        "# Plot data\n",
        "fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
        "axarr[0].plot(X_np)\n",
        "axarr[0].set_xlabel('T')\n",
        "axarr[0].set_title('Entire time series')\n",
        "axarr[1].plot(X_np[:50])\n",
        "axarr[1].set_xlabel('T')\n",
        "axarr[1].set_title('First 50 time points')\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "# Step 5: Save the plot to Google Drive\n",
        "plot_filename = os.path.join(save_dir, 'data_plots.png')\n",
        "plt.savefig(plot_filename)  # Save the plot as a PNG file in Google Drive\n",
        "\n",
        "# Optionally, close the plot to prevent it from displaying in the notebook (you can skip this if you want to see it in the notebook)\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "njNLOBz74tcs",
        "outputId": "ef0c5ee4-399e-4e26-e966-2be7bed51599"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------Iter = 100----------\n",
            "Loss = 199.071335\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 200----------\n",
            "Loss = 189.913132\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 300----------\n",
            "Loss = 181.008652\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 400----------\n",
            "Loss = 171.999329\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 500----------\n",
            "Loss = 163.290268\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 600----------\n",
            "Loss = 155.437408\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 700----------\n",
            "Loss = 148.641205\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 800----------\n",
            "Loss = 142.663635\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 900----------\n",
            "Loss = 137.266693\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1000----------\n",
            "Loss = 131.998032\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1100----------\n",
            "Loss = 127.025391\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1200----------\n",
            "Loss = 122.340469\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1300----------\n",
            "Loss = 117.755432\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1400----------\n",
            "Loss = 113.173683\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1500----------\n",
            "Loss = 108.529991\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1600----------\n",
            "Loss = 103.835609\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1700----------\n",
            "Loss = 99.158119\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1800----------\n",
            "Loss = 94.578285\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 1900----------\n",
            "Loss = 90.053459\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2000----------\n",
            "Loss = 85.630608\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2100----------\n",
            "Loss = 81.399010\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2200----------\n",
            "Loss = 77.379936\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2300----------\n",
            "Loss = 73.659470\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2400----------\n",
            "Loss = 70.324181\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2500----------\n",
            "Loss = 67.407547\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2600----------\n",
            "Loss = 64.974937\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2700----------\n",
            "Loss = 62.824696\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2800----------\n",
            "Loss = 61.135712\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 2900----------\n",
            "Loss = 59.811817\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3000----------\n",
            "Loss = 57.982815\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3100----------\n",
            "Loss = 57.465950\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3200----------\n",
            "Loss = 55.787891\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3300----------\n",
            "Loss = 54.137844\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3400----------\n",
            "Loss = 54.224262\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3500----------\n",
            "Loss = 53.796101\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3600----------\n",
            "Loss = 51.273708\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3700----------\n",
            "Loss = 50.007282\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3800----------\n",
            "Loss = 48.878365\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 3900----------\n",
            "Loss = 49.245266\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4000----------\n",
            "Loss = 50.597046\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4100----------\n",
            "Loss = 47.301025\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4200----------\n",
            "Loss = 45.907280\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4300----------\n",
            "Loss = 45.682964\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4400----------\n",
            "Loss = 46.469959\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4500----------\n",
            "Loss = 44.861366\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4600----------\n",
            "Loss = 43.457058\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4700----------\n",
            "Loss = 43.365196\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4800----------\n",
            "Loss = 43.389565\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 4900----------\n",
            "Loss = 43.494770\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5000----------\n",
            "Loss = 42.471649\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5100----------\n",
            "Loss = 41.965153\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5200----------\n",
            "Loss = 41.381813\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5300----------\n",
            "Loss = 42.425739\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5400----------\n",
            "Loss = 42.129673\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5500----------\n",
            "Loss = 41.487148\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5600----------\n",
            "Loss = 41.223480\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5700----------\n",
            "Loss = 42.294361\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5800----------\n",
            "Loss = 42.309284\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 5900----------\n",
            "Loss = 37.808670\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6000----------\n",
            "Loss = 37.239422\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6100----------\n",
            "Loss = 39.801464\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6200----------\n",
            "Loss = 41.890877\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6300----------\n",
            "Loss = 39.943062\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6400----------\n",
            "Loss = 38.649391\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6500----------\n",
            "Loss = 36.840832\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6600----------\n",
            "Loss = 39.948700\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6700----------\n",
            "Loss = 34.939198\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6800----------\n",
            "Loss = 37.562244\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 6900----------\n",
            "Loss = 37.957436\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7000----------\n",
            "Loss = 37.431484\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7100----------\n",
            "Loss = 38.255024\n",
            "Variable usage = 100.00%\n",
            "----------Iter = 7200----------\n",
            "Loss = 37.948925\n",
            "Variable usage = 100.00%\n",
            "Stopping early\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'cdlinear' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-696e1f794529>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;31m# Verify learned Granger causality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0mGC_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcdlinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0mresults_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'gc_results_{i}.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cdlinear' is not defined"
          ]
        }
      ],
      "source": [
        "for i in range(20):\n",
        "  save_dir = '/content/drive/MyDrive/ngcausality_results/' + 'loren_f40_t1000_layer3/lam=' + str(1+5*i) + '/'\n",
        "\n",
        "  if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "  #Set up model\n",
        "  cmlp = cMLP(X.shape[-1], hidden=[10,10,10], lag=5).to(device=device)\n",
        "\n",
        "  # Train with ISTA\n",
        "  train_loss_list = train_model_ista(\n",
        "    cmlp, X, lam=(1+5*i), lam_ridge=1e-5, lr=5e-5, penalty='H', max_iter=50000,\n",
        "    check_every=100)\n",
        "\n",
        "  # Loss function plot\n",
        "  plt.figure(figsize=(8, 5))\n",
        "  train_loss_np = [loss.cpu().detach().numpy() for loss in train_loss_list]\n",
        "  plt.plot(50 * np.arange(len(train_loss_np)), train_loss_np)\n",
        "  plt.title('cMLP training')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Training steps')\n",
        "  plt.tight_layout()\n",
        "  loss_plot_path = os.path.join(save_dir, f'loss_plot_{1+5*i}.png')\n",
        "  plt.savefig(loss_plot_path)  # Save the loss plot to Google Drive\n",
        "  plt.close()  # Close the plot to prevent it from displaying\n",
        "\n",
        "  # Verify learned Granger causality\n",
        "  GC_est = cmlp.GC().cpu().data.numpy()\n",
        "\n",
        "  results_file_path = os.path.join(save_dir, f'gc_results_{i}.txt')\n",
        "  with open(results_file_path, 'w') as f:\n",
        "    f.write(f'True variable usage = {100 * np.mean(GC)}%\\n')\n",
        "    f.write(f'Estimated variable usage = {100 * np.mean(GC_est)}%\\n')\n",
        "    f.write(f'Accuracy = {100 * np.mean(GC == GC_est)}%\\n')\n",
        "    f.write(f'True positives = {np.sum((GC == 1) & (GC_est == 1))}\\n')\n",
        "    f.write(f'True negatives = {np.sum((GC == 0) & (GC_est == 0))}\\n')\n",
        "    f.write(f'False positives = {np.sum((GC == 0) & (GC_est == 1))}\\n')\n",
        "    f.write(f'False negatives = {np.sum((GC == 1) & (GC_est == 0))}\\n')\n",
        "\n",
        "  # Make figures for Granger causality matrices\n",
        "  fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
        "  axarr[0].imshow(GC, cmap='Blues')\n",
        "  axarr[0].set_title('GC actual')\n",
        "  axarr[0].set_ylabel('Affected series')\n",
        "  axarr[0].set_xlabel('Causal series')\n",
        "  axarr[0].set_xticks([])\n",
        "  axarr[0].set_yticks([])\n",
        "\n",
        "  axarr[1].imshow(GC_est, cmap='Blues', vmin=0, vmax=1, extent=(0, len(GC_est), len(GC_est), 0))\n",
        "  axarr[1].set_title('GC estimated')\n",
        "  axarr[1].set_ylabel('Affected series')\n",
        "  axarr[1].set_xlabel('Causal series')\n",
        "  axarr[1].set_xticks([])\n",
        "  axarr[1].set_yticks([])\n",
        "\n",
        "  # Mark disagreements\n",
        "  for i in range(len(GC_est)):\n",
        "    for j in range(len(GC_est)):\n",
        "        if GC[i, j] != GC_est[i, j]:\n",
        "            rect = plt.Rectangle((j, i-0.05), 1, 1, facecolor='none', edgecolor='red', linewidth=1)\n",
        "            axarr[1].add_patch(rect)\n",
        "\n",
        "  gc_plot_path = os.path.join(save_dir, f'gc_plot_{i}.png')\n",
        "  plt.savefig(gc_plot_path)  # Save the GC plot to Google Drive\n",
        "  plt.close()  # Close the plot to prevent it from displaying\n",
        "\n",
        "  # Verify lag selection\n",
        "  for i in range(len(GC_est)):\n",
        "    # Get true GC\n",
        "    GC_lag = np.zeros((5, len(GC_est)))\n",
        "    GC_lag[:3, GC[i].astype(bool)] = 1.0\n",
        "\n",
        "    # Get estimated GC\n",
        "    GC_est_lag = cmlp.GC(ignore_lag=False, threshold=False)[i].cpu().data.numpy().T[::-1]\n",
        "\n",
        "    # Make figures for lag-based GC\n",
        "    fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
        "    axarr[0].imshow(GC_lag, cmap='Blues', extent=(0, len(GC_est), 5, 0))\n",
        "    axarr[0].set_title(f'Series {i + 1} true GC')\n",
        "    axarr[0].set_ylabel('Lag')\n",
        "    axarr[0].set_xlabel('Series')\n",
        "    axarr[0].set_xticks(np.arange(len(GC_est)) + 0.5)\n",
        "    axarr[0].set_xticklabels(range(len(GC_est)))\n",
        "    axarr[0].set_yticks(np.arange(5) + 0.5)\n",
        "    axarr[0].set_yticklabels(range(1, 5 + 1))\n",
        "    axarr[0].tick_params(axis='both', length=0)\n",
        "\n",
        "    axarr[1].imshow(GC_est_lag, cmap='Blues', extent=(0, len(GC_est), 5, 0))\n",
        "    axarr[1].set_title(f'Series {i + 1} estimated GC')\n",
        "    axarr[1].set_ylabel('Lag')\n",
        "    axarr[1].set_xlabel('Series')\n",
        "    axarr[1].set_xticks(np.arange(len(GC_est)) + 0.5)\n",
        "    axarr[1].set_xticklabels(range(len(GC_est)))\n",
        "    axarr[1].set_yticks(np.arange(5) + 0.5)\n",
        "    axarr[1].set_yticklabels(range(1, 5 + 1))\n",
        "    axarr[1].tick_params(axis='both', length=0)\n",
        "\n",
        "    # Mark nonzeros\n",
        "    for k in range(len(GC_est)):\n",
        "        for j in range(5):\n",
        "            if GC_est_lag[j, k] > 0.0:\n",
        "                rect = plt.Rectangle((k, j), 1, 1, facecolor='none', edgecolor='green', linewidth=1.0)\n",
        "                axarr[1].add_patch(rect)\n",
        "\n",
        "    lag_gc_plot_path = os.path.join(save_dir, f'lag_gc_plot_{j}_{i}.png')\n",
        "    plt.savefig(lag_gc_plot_path)  # Save lag GC plot to Google Drive\n",
        "    plt.close()  # Close the plot to prevent it from displaying\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}